# Project Poisoning

This branch contains the Data Poisoning & Backdoor project for the AI Security Portfolio.

## Goals
- Create a small data poisoning / backdoor attack demo
- Train and evaluate a poisoned model
- Explore simple detection heuristics
- Document findings and limitations

## Structure
- `/notebooks` → Jupyter notebooks for poisoning experiments
- `/data` → Clean and poisoned datasets
- `/src` → Scripts for poisoning, training, and detection
- `/results` → Example poisoned samples & model evaluations
